{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data & feature creation\n",
    "* input: file\n",
    "* output: df_features, df_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is from\n",
    "https://www.eecs.qmul.ac.uk/mmv/datasets/deap/readme.html#prep\n",
    "\n",
    "Know\n",
    "1. https://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = cPickle.load(open('data/data_preprocessed_python/s01.dat', 'rb'),encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'labels', b'data'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_x = x[b'data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 8064)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.71,  7.6 ,  6.9 ,  7.83],\n",
       "       [ 8.1 ,  7.31,  7.28,  8.47],\n",
       "       [ 8.58,  7.54,  9.  ,  7.08],\n",
       "       [ 4.94,  6.01,  6.12,  8.06],\n",
       "       [ 6.96,  3.92,  7.19,  6.05],\n",
       "       [ 8.27,  3.92,  7.  ,  8.03],\n",
       "       [ 7.44,  3.73,  7.08,  7.04],\n",
       "       [ 7.32,  2.55,  6.32,  5.87],\n",
       "       [ 4.04,  3.29,  3.62,  5.99],\n",
       "       [ 1.99,  4.86,  2.04,  7.09],\n",
       "       [ 2.99,  2.36,  3.63,  6.24],\n",
       "       [ 2.71,  2.77,  3.4 ,  7.35],\n",
       "       [ 1.95,  3.12,  2.87,  6.18],\n",
       "       [ 4.18,  2.24,  3.04,  5.04],\n",
       "       [ 3.17,  8.08,  2.91,  5.04],\n",
       "       [ 6.81,  7.44,  8.15,  7.14],\n",
       "       [ 2.46,  6.91,  6.77,  6.41],\n",
       "       [ 7.23,  7.15,  6.94,  8.01],\n",
       "       [ 7.17,  8.  ,  8.1 ,  6.79],\n",
       "       [ 8.26,  7.91,  7.19,  8.13],\n",
       "       [ 9.  ,  7.95,  8.37,  7.86],\n",
       "       [ 7.09,  2.08,  7.06,  7.37],\n",
       "       [ 8.15,  3.01,  7.37,  7.9 ],\n",
       "       [ 7.04,  7.09,  8.01,  8.22],\n",
       "       [ 8.86,  7.21,  8.65,  7.21],\n",
       "       [ 7.28,  7.27,  7.41,  8.24],\n",
       "       [ 7.35,  6.95,  7.03,  7.29],\n",
       "       [ 3.88,  3.35,  4.01,  7.87],\n",
       "       [ 1.36,  2.27,  3.  ,  8.14],\n",
       "       [ 2.08,  2.99,  3.22,  7.33],\n",
       "       [ 3.03,  8.14,  2.86,  8.04],\n",
       "       [ 2.28,  8.  ,  3.27,  3.95],\n",
       "       [ 3.81,  3.85,  4.78,  5.13],\n",
       "       [ 2.28,  7.09,  7.28,  6.92],\n",
       "       [ 2.06,  8.15,  8.05,  5.18],\n",
       "       [ 2.9 ,  6.92,  6.5 ,  3.87],\n",
       "       [ 2.31,  6.88,  3.1 ,  6.77],\n",
       "       [ 3.33,  7.18,  6.54,  6.62],\n",
       "       [ 3.24,  6.18,  7.87,  6.15],\n",
       "       [ 5.1 ,  7.12,  6.17,  5.97]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_label = pd.DataFrame(x[b'labels'])\n",
    "\n",
    "df_label.columns = ['valence', 'arousal', 'dominance', 'liking']\n",
    "\n",
    "df_label.drop(['dominance', 'liking'],axis=1,inplace=True)\n",
    "\n",
    "df_label.valence = pd.cut(df_label.valence,bins=2,right=[0,5,10],labels=['high', 'low'])\n",
    "df_label.arousal = pd.cut(df_label.arousal,bins=2,right=[0,5,10],labels=['high', 'low'])\n",
    "\n",
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_x = x[b'data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract list\n",
    "\n",
    "stats\n",
    "1. mean\n",
    "2. median\n",
    "3. max\n",
    "4. min\n",
    "5. std dev\n",
    "6. variance\n",
    "7. range\n",
    "8. skewness\n",
    "9. kurtosis\n",
    "\n",
    "from\n",
    "1. 0:806, 10 batches\n",
    "4. all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 8064)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_x[0,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,  806, 1612, 2418, 3225, 4031, 4837, 5644, 6450, 7256, 8063])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEPS = np.linspace(0,arr_x.shape[2]-1,11).astype(int); STEPS\n",
    "\n",
    "ops = [np.mean, np.median, np.max, np.min ,np.std, np.var, skew, kurtosis]\n",
    "# don't forget range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(arr_x, axis=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.stack([op(arr_x, axis=2) for op in ops], axis=2);a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = a[:,:,2]-a[:,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add range\n",
    "a = np.dstack((a,a[:,:,2]-a[:,:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 9)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 806, 1612, 2418, 3225, 4031, 4837, 5644, 6450, 7256, 8063])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEPS[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = []\n",
    "for start,end in zip(STEPS.tolist(),STEPS[1:].tolist()):\n",
    "    ran = np.stack([op(arr_x[:,:,start:end], axis=2) for op in ops], axis=2)\n",
    "    ran = np.dstack((ran,ran[:,:,2]-ran[:,:,3]))\n",
    "    b.append(ran)\n",
    "\n",
    "\n",
    "b = np.concatenate(b,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 90)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 40, 1]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(arr_x.shape[:2])+[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.full(list(arr_x.shape[:2])+[1],PAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.reshape(np.repeat(np.arange(arr_x.shape[0]), arr_x.shape[1]),list(arr_x.shape[:2])+[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.concatenate((a,b,c,d),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 101)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = pd.get_dummies(df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence_high</th>\n",
       "      <th>valence_low</th>\n",
       "      <th>arousal_high</th>\n",
       "      <th>arousal_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    valence_high  valence_low  arousal_high  arousal_low\n",
       "0              0            1             0            1\n",
       "1              0            1             0            1\n",
       "2              0            1             0            1\n",
       "3              1            0             0            1\n",
       "4              0            1             1            0\n",
       "5              0            1             1            0\n",
       "6              0            1             1            0\n",
       "7              0            1             1            0\n",
       "8              1            0             1            0\n",
       "9              1            0             1            0\n",
       "10             1            0             1            0\n",
       "11             1            0             1            0\n",
       "12             1            0             1            0\n",
       "13             1            0             1            0\n",
       "14             1            0             0            1\n",
       "15             0            1             0            1\n",
       "16             1            0             0            1\n",
       "17             0            1             0            1\n",
       "18             0            1             0            1\n",
       "19             0            1             0            1\n",
       "20             0            1             0            1\n",
       "21             0            1             1            0\n",
       "22             0            1             1            0\n",
       "23             0            1             0            1\n",
       "24             0            1             0            1\n",
       "25             0            1             0            1\n",
       "26             0            1             0            1\n",
       "27             1            0             1            0\n",
       "28             1            0             1            0\n",
       "29             1            0             1            0\n",
       "30             1            0             0            1\n",
       "31             1            0             0            1\n",
       "32             1            0             1            0\n",
       "33             1            0             0            1\n",
       "34             1            0             0            1\n",
       "35             1            0             0            1\n",
       "36             1            0             0            1\n",
       "37             1            0             0            1\n",
       "38             1            0             0            1\n",
       "39             1            0             0            1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applied for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('data/data_preprocessed_python/*.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAT = re.search(r\"\\d+\",os.path.basename(files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(PAT.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readDEAPFile(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        x = cPickle.load(f,encoding='bytes')\n",
    "    return x[b'data'], x[b'labels']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processDEAP(file):\n",
    "    PAT = re.search(r\"\\d+\",os.path.basename(file))\n",
    "    PAT = int(PAT.group(0))\n",
    "    \n",
    "    arr_x, y = readDEAPFile(file)\n",
    "    \n",
    "    # label process\n",
    "    df_label = pd.DataFrame(y)\n",
    "\n",
    "    df_label.columns = ['valence', 'arousal', 'dominance', 'liking']\n",
    "\n",
    "    df_label.drop(['dominance', 'liking'],axis=1,inplace=True)\n",
    "\n",
    "    df_label.valence = pd.cut(df_label.valence,bins=2,right=[0,5,10],labels=['high', 'low'])\n",
    "    df_label.arousal = pd.cut(df_label.arousal,bins=2,right=[0,5,10],labels=['high', 'low'])\n",
    "    df_label = pd.get_dummies(df_label)\n",
    "    \n",
    "    \n",
    "    # features process\n",
    "    STEPS = np.linspace(0,arr_x.shape[2]-1,11).astype(int); STEPS\n",
    "\n",
    "    ops = [np.mean, np.median, np.max, np.min ,np.std, np.var, skew, kurtosis] # not include range\n",
    "    \n",
    "    # features process: all\n",
    "    a = np.stack([op(arr_x, axis=2) for op in ops], axis=2)\n",
    "    a = np.dstack((a,a[:,:,2]-a[:,:,3]))\n",
    "    \n",
    "    # features process: the 10-batch\n",
    "    b = []\n",
    "    for start,end in zip(STEPS.tolist(),STEPS[1:].tolist()):\n",
    "        ran = np.stack([op(arr_x[:,:,start:end], axis=2) for op in ops], axis=2)\n",
    "        ran = np.dstack((ran,ran[:,:,2]-ran[:,:,3]))\n",
    "        b.append(ran)\n",
    "    b = np.concatenate(b,axis=2)\n",
    "    \n",
    "    # features process: identities\n",
    "    c = np.reshape(np.repeat(np.arange(arr_x.shape[0]), arr_x.shape[1]),list(arr_x.shape[:2])+[1])\n",
    "    d = np.full(list(arr_x.shape[:2])+[1],PAT)\n",
    "    \n",
    "    features = np.concatenate((a,b,c,d),axis=2)\n",
    "    \n",
    "    return features, df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "dfs_y = []\n",
    "for file in files:\n",
    "    x, df_y = processDEAP(file)\n",
    "    xs.append(x)\n",
    "    dfs_y.append(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.stack(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 40, 40, 101)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape # paticipant, experiment, ch, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = [df.values for df in dfs_y]\n",
    "ys = np.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 40, 4)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.shape # paticipant, experiment, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/x.dat',mode='wb') as f:\n",
    "    pickle.dump(xs, f)\n",
    "with open('data/y.dat',mode='wb') as f:\n",
    "    pickle.dump(ys, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/x.dat', mode='rb') as f:\n",
    "    xs = pickle.load(f)\n",
    "with open('data/y.dat', mode='rb') as f:\n",
    "    ys = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 50\n",
    "nbClasses = 2\n",
    "nbEpoch = 5\n",
    "CH, DATA = 40, 101\n",
    "nbFilters = 100\n",
    "nbConv = 3\n",
    "NEpoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nbFilters, (nbConv, nbConv), input_shape=(1,CH,DATA), activation='tanh', data_format='channels_first'))\n",
    "model.add(Convolution2D(nbFilters, (nbConv, nbConv), activation='tanh'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(nbClasses, activation='softplus'))\n",
    "\n",
    "sgd = SGD(lr=0.00001, decay= 1e-6, momentum= 0.9, nesterov=True)\n",
    "\n",
    "model.compile(sgd, 'categorical_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 100, 38, 99)       1000      \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 98, 36, 100)       89200     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 49, 18, 100)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 49, 18, 100)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 88200)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               11289728  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 11,380,186\n",
      "Trainable params: 11,380,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 1, 40, 101)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat, exp, ch ,data = xs.shape\n",
    "X = xs.reshape(pat*exp, 1, ch, data); X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 2)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat, exp, label = ys.shape\n",
    "Y = ys.reshape(pat*exp,-1)[:,:2]; Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.8399 - val_loss: 0.6960\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.7954 - val_loss: 0.6933\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.7362 - val_loss: 0.6976\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.7463 - val_loss: 0.6916\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.7354 - val_loss: 0.6943\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.7120 - val_loss: 0.6909\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.7158 - val_loss: 0.6918\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.7094 - val_loss: 0.6871\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 62s - loss: 0.7002 - val_loss: 0.6882\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 55s - loss: 0.6974 - val_loss: 0.6891\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.7073 - val_loss: 0.6867\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 59s - loss: 0.6966 - val_loss: 0.6894\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 55s - loss: 0.7035 - val_loss: 0.6878\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.7034 - val_loss: 0.6895\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.7058 - val_loss: 0.6873\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.7005 - val_loss: 0.6908\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.7010 - val_loss: 0.6895\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6989 - val_loss: 0.6915\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6984 - val_loss: 0.6909\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6927 - val_loss: 0.6903\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6965 - val_loss: 0.6915\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6923 - val_loss: 0.6927\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6949 - val_loss: 0.6904\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6966 - val_loss: 0.6920\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6891 - val_loss: 0.6910\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6924 - val_loss: 0.6906\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6951 - val_loss: 0.6881\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6889 - val_loss: 0.6886\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6902 - val_loss: 0.6865\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6891 - val_loss: 0.6882\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6901 - val_loss: 0.6878\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6877 - val_loss: 0.6861\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6852 - val_loss: 0.6873\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6962 - val_loss: 0.6891\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6914 - val_loss: 0.6901\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6942 - val_loss: 0.6879\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6973 - val_loss: 0.6893\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6876 - val_loss: 0.6887\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6953 - val_loss: 0.6875\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6907 - val_loss: 0.6849\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6887 - val_loss: 0.6868\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6924 - val_loss: 0.6866\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6947 - val_loss: 0.6859\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6922 - val_loss: 0.6861\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6955 - val_loss: 0.6867\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6833 - val_loss: 0.6873\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6897 - val_loss: 0.6852\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6910 - val_loss: 0.6860\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6960 - val_loss: 0.6855\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6869 - val_loss: 0.6869\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6929 - val_loss: 0.6855\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6933 - val_loss: 0.6866\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6890 - val_loss: 0.6859\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6914 - val_loss: 0.6862\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6910 - val_loss: 0.6854\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6853 - val_loss: 0.6854\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6888 - val_loss: 0.6852\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 56s - loss: 0.6909 - val_loss: 0.6847\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6766 - val_loss: 0.6852\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6869 - val_loss: 0.6851\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6790 - val_loss: 0.6856\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6894 - val_loss: 0.6836\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6851 - val_loss: 0.6844\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6899 - val_loss: 0.6859\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6795 - val_loss: 0.6845\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6867 - val_loss: 0.6836\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6808 - val_loss: 0.6827\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6825 - val_loss: 0.6824\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6881 - val_loss: 0.6847\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6864 - val_loss: 0.6852\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6883 - val_loss: 0.6823\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6834 - val_loss: 0.6821\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6864 - val_loss: 0.6827\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6847 - val_loss: 0.6832\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6808 - val_loss: 0.6828\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6873 - val_loss: 0.6829\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6873 - val_loss: 0.6810\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6872 - val_loss: 0.6824\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6808 - val_loss: 0.6813\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6874 - val_loss: 0.6808\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240/1240 [==============================] - 53s - loss: 0.6827 - val_loss: 0.6839\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6826 - val_loss: 0.6824\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6778 - val_loss: 0.6829\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6814 - val_loss: 0.6831\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6802 - val_loss: 0.6838\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6811 - val_loss: 0.6862\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6854 - val_loss: 0.6837\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6833 - val_loss: 0.6821\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6808 - val_loss: 0.6830\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6744 - val_loss: 0.6813\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6726 - val_loss: 0.6813\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6775 - val_loss: 0.6829\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6828 - val_loss: 0.6819\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6780 - val_loss: 0.6813\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6767 - val_loss: 0.6816\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6800 - val_loss: 0.6832\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6819 - val_loss: 0.6834\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6831 - val_loss: 0.6823\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6794 - val_loss: 0.6822\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6694 - val_loss: 0.6824\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6822 - val_loss: 0.6813\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6820 - val_loss: 0.6816\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6793 - val_loss: 0.6818\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6887 - val_loss: 0.6847\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6834 - val_loss: 0.6837\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6819 - val_loss: 0.6839\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6773 - val_loss: 0.6820\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6874 - val_loss: 0.6828\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6854 - val_loss: 0.6824\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6818 - val_loss: 0.6834\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6803 - val_loss: 0.6834\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6797 - val_loss: 0.6839\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6774 - val_loss: 0.6830\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6818 - val_loss: 0.6828\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6801 - val_loss: 0.6827\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6804 - val_loss: 0.6838\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6783 - val_loss: 0.6821\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6791 - val_loss: 0.6821\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6809 - val_loss: 0.6836\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6784 - val_loss: 0.6827\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6758 - val_loss: 0.6837\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6836 - val_loss: 0.6842\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6686 - val_loss: 0.6824\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6782 - val_loss: 0.6821\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6714 - val_loss: 0.6818\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6793 - val_loss: 0.6823\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6771 - val_loss: 0.6815\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6751 - val_loss: 0.6813\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6777 - val_loss: 0.6828\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6745 - val_loss: 0.6813\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6700 - val_loss: 0.6802\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6692 - val_loss: 0.6807\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6754 - val_loss: 0.6812\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6731 - val_loss: 0.6798\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6752 - val_loss: 0.6807\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6667 - val_loss: 0.6809\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6736 - val_loss: 0.6795\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6652 - val_loss: 0.6795\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6757 - val_loss: 0.6796\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6703 - val_loss: 0.6791\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6723 - val_loss: 0.6791\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6737 - val_loss: 0.6786\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6798 - val_loss: 0.6790\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6697 - val_loss: 0.6781\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6667 - val_loss: 0.6765\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6705 - val_loss: 0.6771\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6710 - val_loss: 0.6767\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6679 - val_loss: 0.6748\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6695 - val_loss: 0.6763\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6687 - val_loss: 0.6763\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6770 - val_loss: 0.6754\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6702 - val_loss: 0.6763\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6629 - val_loss: 0.6744\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6746 - val_loss: 0.6741\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 52s - loss: 0.6586 - val_loss: 0.6762\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 56s - loss: 0.6765 - val_loss: 0.6750\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6670 - val_loss: 0.6744\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 57s - loss: 0.6632 - val_loss: 0.6743\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 56s - loss: 0.6693 - val_loss: 0.6733\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 56s - loss: 0.6661 - val_loss: 0.6759\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240/1240 [==============================] - 55s - loss: 0.6620 - val_loss: 0.6736\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 55s - loss: 0.6716 - val_loss: 0.6733\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 55s - loss: 0.6702 - val_loss: 0.6739\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 55s - loss: 0.6656 - val_loss: 0.6743\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 55s - loss: 0.6768 - val_loss: 0.6724\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 56s - loss: 0.6724 - val_loss: 0.6737\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 57s - loss: 0.6704 - val_loss: 0.6741\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 55s - loss: 0.6673 - val_loss: 0.6737\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 55s - loss: 0.6601 - val_loss: 0.6719\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6755 - val_loss: 0.6722\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6665 - val_loss: 0.6726\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6672 - val_loss: 0.6729\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6645 - val_loss: 0.6726\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6647 - val_loss: 0.6717\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6719 - val_loss: 0.6738\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6555 - val_loss: 0.6735\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6664 - val_loss: 0.6732\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6646 - val_loss: 0.6721\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6655 - val_loss: 0.6719\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6591 - val_loss: 0.6715\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6637 - val_loss: 0.6717\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6577 - val_loss: 0.6719\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6680 - val_loss: 0.6724\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6616 - val_loss: 0.6735\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6535 - val_loss: 0.6725\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6643 - val_loss: 0.6730\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6657 - val_loss: 0.6724\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6617 - val_loss: 0.6710\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6693 - val_loss: 0.6709\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6615 - val_loss: 0.6706\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6648 - val_loss: 0.6687\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6653 - val_loss: 0.6700\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6527 - val_loss: 0.6700\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6540 - val_loss: 0.6708\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6615 - val_loss: 0.6676\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6526 - val_loss: 0.6668\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6510 - val_loss: 0.6662\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6545 - val_loss: 0.6666\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6560 - val_loss: 0.6668\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6503 - val_loss: 0.6658\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6571 - val_loss: 0.6660\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6529 - val_loss: 0.6670\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6696 - val_loss: 0.6677\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6582 - val_loss: 0.6694\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6682 - val_loss: 0.6680\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6581 - val_loss: 0.6686\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6573 - val_loss: 0.6693\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6449 - val_loss: 0.6694\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6546 - val_loss: 0.6700\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6523 - val_loss: 0.6686\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6624 - val_loss: 0.6692\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6471 - val_loss: 0.6703\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6607 - val_loss: 0.6705\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6522 - val_loss: 0.6692\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6498 - val_loss: 0.6697\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6517 - val_loss: 0.6692\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6555 - val_loss: 0.6691\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6537 - val_loss: 0.6687\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 53s - loss: 0.6539 - val_loss: 0.6683\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6585 - val_loss: 0.6684\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6581 - val_loss: 0.6671\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6446 - val_loss: 0.6678\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 54s - loss: 0.6470 - val_loss: 0.6672\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 56s - loss: 0.6454 - val_loss: 0.6690\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6455 - val_loss: 0.6688\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6609 - val_loss: 0.6696\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6521 - val_loss: 0.6697\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6454 - val_loss: 0.6703\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6403 - val_loss: 0.6719\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6581 - val_loss: 0.6714\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6476 - val_loss: 0.6706\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6493 - val_loss: 0.6693\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6396 - val_loss: 0.6696\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6557 - val_loss: 0.6692\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 50s - loss: 0.6362 - val_loss: 0.6687\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6481 - val_loss: 0.6686\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6468 - val_loss: 0.6688\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6456 - val_loss: 0.6685\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6586 - val_loss: 0.6693\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6586 - val_loss: 0.6704\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240/1240 [==============================] - 51s - loss: 0.6426 - val_loss: 0.6708\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6402 - val_loss: 0.6700\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6544 - val_loss: 0.6671\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6580 - val_loss: 0.6674\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6387 - val_loss: 0.6684\n",
      "Train on 1240 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6524 - val_loss: 0.6687\n",
      "Epoch 2/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6503 - val_loss: 0.6685\n",
      "Epoch 3/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6381 - val_loss: 0.6686\n",
      "Epoch 4/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6472 - val_loss: 0.6683\n",
      "Epoch 5/5\n",
      "1240/1240 [==============================] - 51s - loss: 0.6322 - val_loss: 0.6678\n"
     ]
    }
   ],
   "source": [
    "accAll = []\n",
    "for _ in range(NEpoch):\n",
    "    model.fit(X,Y,batch_size=batchSize, epochs=nbEpoch, validation_split=1/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 40, 4)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 22s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.60726239234209056"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('originalNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
